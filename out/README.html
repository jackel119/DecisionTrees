<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, minimal-ui">
    <title>Decision Trees</title>
    <link type="text/css" rel="stylesheet" href="assets/css/github-markdown.css">
    <link type="text/css" rel="stylesheet" href="assets/css/pilcrow.css">
    <link type="text/css" rel="stylesheet" href="assets/css/hljs-github.min.css"/>
  </head>
  <body>
    <article class="markdown-body"><h1 id="decision-trees"><a class="header-link" href="#decision-trees"></a>Decision Trees</h1>
<p>This is a simple implementation of decision trees.</p>
<p>The interface is inspired by other popular machine learning libraries such as <code>Keras</code> and <code>SKLearn</code>, and hence the main <code>DecisionTreeClassifier</code> class has methods <code>fit</code>, <code>predict</code>, <code>evaluate</code>.</p>
<h3 id="instantiation-and-training"><a class="header-link" href="#instantiation-and-training"></a>Instantiation and training</h3>
<p>To use, first import (from top level of this folder, similar to what can be found in <code>main.py</code>)</p>
<pre class="hljs"><code><span class="hljs-keyword">from</span> decisiontrees <span class="hljs-keyword">import</span> DecisionTreeClassifier
dt = DecisionTreeClassifier()</code></pre><p>Then, simply <code>fit</code> the model on some data:</p>
<pre class="hljs"><code>dt.fit(training_data)</code></pre><p>The input data format must be a 2-dimensional <code>numpy</code> <code>ndarray</code>, with the last column being integer labels. For example, with the given datasets in the coursework, you can do:</p>
<pre class="hljs"><code><span class="hljs-keyword">with</span> open(<span class="hljs-string">'data/clean_dataset.txt'</span>) <span class="hljs-keyword">as</span> clean_dataset:
  training_data = np.loadtxt(clean_dataset)</code></pre><h3 id="making-predictions-and-evaluations"><a class="header-link" href="#making-predictions-and-evaluations"></a>Making predictions and evaluations</h3>
<p>To make a prediction, simply call <code>predict</code>:</p>
<pre class="hljs"><code>dt.predict(test_data)</code></pre><p>where <code>test_data</code> is the exact same format as the training data, but without the last column (of labels).</p>
<p>There is also an <code>evaluate</code> function:</p>
<pre class="hljs"><code>dt.evaluate(labeled_test_data)</code></pre><p>where <code>labeled_test_data</code> is the same format as <code>training_data</code> (i.e. it is labeled). What this will do is internally call <code>predict</code> on the features, then compare with the actual labels in order to compute accuracy, precision and recall (of each class), as well as a confusion matrix (as a <code>numpy</code> array, with predictions as columns and actual labels as rows). This is all returned as a dictionary.</p>
<p>For example:</p>
<pre class="hljs"><code><span class="hljs-meta">&gt;&gt;&gt; </span>evaluation = dt.evaluate(labeled_test_data)
<span class="hljs-meta">&gt;&gt;&gt; </span>evaluation[<span class="hljs-string">'accuracy'</span>]
<span class="hljs-number">0.975</span>
<span class="hljs-meta">&gt;&gt;&gt; </span>evaluation[<span class="hljs-string">'stats'</span>]
{
  <span class="hljs-string">'recalls'</span>: [<span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">0.9878048780487805</span>, <span class="hljs-number">1.0</span>],
  <span class="hljs-string">'precisions'</span>: [<span class="hljs-number">1.0</span>, <span class="hljs-number">0.9857142857142858</span>, <span class="hljs-number">1.0</span>, <span class="hljs-number">1.0</span>],
  <span class="hljs-string">'f1'</span>: [<span class="hljs-number">1.0</span>, <span class="hljs-number">0.9928057553956835</span>, <span class="hljs-number">0.9938650306748467</span>, <span class="hljs-number">1.0</span>]
}
<span class="hljs-meta">&gt;&gt;&gt; </span>evaluation[<span class="hljs-string">'confusion_matrix'</span>]
array([[<span class="hljs-number">79</span>,  <span class="hljs-number">0</span>,  <span class="hljs-number">0</span>,  <span class="hljs-number">0</span>],
       [ <span class="hljs-number">0</span>, <span class="hljs-number">69</span>,  <span class="hljs-number">0</span>,  <span class="hljs-number">0</span>],
       [ <span class="hljs-number">0</span>,  <span class="hljs-number">1</span>, <span class="hljs-number">81</span>,  <span class="hljs-number">0</span>],
       [ <span class="hljs-number">0</span>,  <span class="hljs-number">0</span>,  <span class="hljs-number">0</span>, <span class="hljs-number">70</span>]])</code></pre><p>Note that the lists of <code>stats</code> are indexed by their class label minus one, i.e. the value at the 0th index of the <code>precision</code> list is the precision of class 1.</p>
<h3 id="tree-representations"><a class="header-link" href="#tree-representations"></a>Tree Representations</h3>
<p>You can also visualize the tree, using <code>dt.plot_tree()</code>, which will give you something like this:</p>
<p class="img-container"><img src="images/tree.png" alt="Tree Example"></p>
<h3 id="tree-height-and-average-height"><a class="header-link" href="#tree-height-and-average-height"></a>Tree Height and Average Height</h3>
<p>There is also a <code>height</code> method.</p>
<pre class="hljs"><code>&gt;&gt;&gt; <span class="hljs-selector-tag">dt</span>.<span class="hljs-attribute">height</span>()
<span class="hljs-number">8</span></code></pre><h3 id="random-forest-model"><a class="header-link" href="#random-forest-model"></a>Random Forest Model</h3>
<p>We also wrote a Random Forest extension, under the <code>RandomForestClassifier</code> class. It has the exact same interface as <code>DecisionTreeClassifier</code> (apart from depth).</p>
<pre class="hljs"><code><span class="hljs-keyword">from</span> decisiontrees <span class="hljs-keyword">import</span> RandomForestClassifier

rf = RandomForestClassifier()
rf.fit(train_data)
predictions = rf.predict(test_data)</code></pre>    </article>
  </body>
</html>
